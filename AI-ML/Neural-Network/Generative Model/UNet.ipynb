{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8998e745-42fd-4862-b072-bad62170c411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "from einops import einsum, rearrange, reduce\n",
    "from functools import partial\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcd50cb-7cfa-4056-b6c2-a8b6ef1ce88f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "460f46e5-8b0b-45cd-9f6d-7cc31e9c13e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = th.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f7ebfe-8845-4717-8453-4a90110b2bd5",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "591278a9-286a-4ba2-a70c-8ea15ed46d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02d56ee1-bb8d-4929-871c-b855eb37c86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary:\n",
    "#b'batch_label': b'training batch 1 of 5'\n",
    "#b'labels': labels for each image\n",
    "#b'data': image array\n",
    "#b'filenames': filenames of the images\n",
    "flattened_images = unpickle(\"./cifar-10-batches-py/data_batch_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c7cd0d1-444e-44b3-93d5-fe25e5cfd2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shape of flattened_images[b'data']: (batch_size, height*width*channels)\n",
    "\n",
    "#input shape: (batch_size, height*width*channels)\n",
    "def channelizeImages(flattened_images):\n",
    "    #reshape to (batch_size, channels, height*width)\n",
    "    images = rearrange(flattened_images[b'data'], 'b (c i) -> b c i', c=3, i=32*32)\n",
    "    #reshape to (batch_size, channels, height, width)\n",
    "    images = rearrange(images, 'b c (h w) -> b c h w', h=32, w=32)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1a77926-b85a-45a8-90ad-13579ad6c7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3, 32, 32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = channelizeImages(flattened_images)\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1861c83d-1307-4dd3-9fce-8b9ae267d03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7a72980b1dc0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(rearrange(images[12,...], 'c h w -> h w c'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85088dc5-173c-4849-aef8-5d477c20a603",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data, sample_size):\n",
    "        self.data = data\n",
    "        self.sample_size = sample_size\n",
    "    def __len__(self):\n",
    "        return self.sample_size\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c3bee5-1ad8-4005-8ae6-524bfc6ff8f4",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b7ef859-042c-41a6-9fab-7a7f0739c14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageDataset(images, len(images))\n",
    "data_loader = DataLoader(dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a78cfc2b-e829-4b94-83a0-cca1237bd296",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34eaea55-a15c-4f79-83c3-2d73585f8fce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 32, 32])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(next(data_iter)/155.).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f865b1-a687-4517-89d5-0bcadf2c3d89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee96746a-363a-4d0c-9f9a-cc0eca6e3abc",
   "metadata": {},
   "source": [
    "# Vanilla UNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d0121b-f76b-48f5-a55c-1092edcb7fc9",
   "metadata": {},
   "source": [
    "Reproduced from paper  <a style=\"display:inline\" href=\"https://arxiv.org/abs/1505.04597\">U-Net: Convolutional Networks for Biomedical Image Segmentation\n",
    " </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "103ffb0e-4ffe-4a1f-91cb-a885f632898d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size=3, padding=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channel, out_channel, kernel_size=kernel_size, padding=padding)\n",
    "        self.conv2 = nn.Conv2d(out_channel, out_channel, kernel_size=kernel_size, padding=padding)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        return self.conv2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15209977-10f9-4da3-ae99-2c98a3cf22d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Upsample(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, scale_factor, padding=1):\n",
    "        super().__init__()\n",
    "        self.up = nn.Upsample(scale_factor=scale_factor, mode='nearest')\n",
    "        self.conv = nn.Conv2d(in_channel, out_channel, kernel_size=3, padding=padding)\n",
    "    def forward(self, x):\n",
    "        x = self.up(x)\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80a93590-19c6-4c23-80b6-7d0bad584fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaUNet(nn.Module):\n",
    "    def __init__(self, in_channel, channels, padding=1):\n",
    "        super().__init__()\n",
    "        self.in_channel = in_channel\n",
    "        self.channels = channels\n",
    "        self.down_channels = list(zip(channels[:-2], channels[1:-1]))\n",
    "        self.up_channels = list(zip(reversed(channels[2:]), reversed(channels[1:-1])))\n",
    "        \n",
    "        self.in_conv = nn.Conv2d(in_channel, channels[0], kernel_size=3, padding=padding)\n",
    "        self.down_stage = nn.ModuleList()\n",
    "        self.mid_stage = Block(channels[-2], channels[-1], kernel_size=3, padding=padding)\n",
    "        self.up_stage = nn.ModuleList()\n",
    "        \n",
    "        for in_ch, out_ch in self.down_channels:\n",
    "            self.down_stage.append(nn.ModuleList([Block(in_ch, out_ch, kernel_size=3, padding=padding),\n",
    "                                                  nn.MaxPool2d(kernel_size=2, stride=2)]))\n",
    "        for in_ch, out_ch in self.up_channels:\n",
    "            self.up_stage.append(nn.ModuleList([Upsample(in_ch, out_ch, scale_factor=2, padding=padding),\n",
    "                                                Block(in_ch, out_ch, kernel_size=3, padding=padding)]))\n",
    "        self.out_conv = nn.Conv2d(channels[1], in_channel, kernel_size=3, padding=padding)\n",
    "    def forward(self, x):\n",
    "        resnet = []\n",
    "        x = self.in_conv(x)\n",
    "        for block, down_sample in self.down_stage:\n",
    "            x = block(x)\n",
    "            resnet.append(x)\n",
    "            x = down_sample(x)\n",
    "        x = self.mid_stage(x)\n",
    "        for block, up_sample in self.up_stage:\n",
    "            x = up_sample(x)\n",
    "            x = block(th.cat((x, self.crop(resnet.pop(), x)), dim=1))\n",
    "        x = self.out_conv(x)\n",
    "        return x\n",
    "    def crop(self, x, x_crop):\n",
    "        crop_height, crop_width = x_crop.shape[2:]\n",
    "        height, width = x.shape[2:]\n",
    "        ix = int((height-crop_height)/2)\n",
    "        iy = int((width-crop_width)/2)\n",
    "        return x[...,ix:ix+crop_height, iy:iy+crop_width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0e3eb0c-e77d-4b85-813f-1b898cf23962",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channel = 3\n",
    "channels = [32, 64, 128]\n",
    "\n",
    "vanilla_unet = VanillaUNet(in_channel, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c2603a6-746f-400f-8de0-f8569a990c9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VanillaUNet(\n",
       "  (in_conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (down_stage): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): Block(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (mid_stage): Block(\n",
       "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  )\n",
       "  (up_stage): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): Upsample(\n",
       "        (up): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "      (1): Block(\n",
       "        (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out_conv): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vanilla_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a3983e7-eec7-4754-81cb-11555e853b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): ModuleList(\n",
       "    (0): Block(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vanilla_unet.down_stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c0e19542-0235-4ae2-a76e-536627f643fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "print(vanilla_unet(next(data_iter)/155.).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bce8f5-810f-423e-a14c-4b0d8bfc9415",
   "metadata": {},
   "source": [
    "# Attention-UNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcdbd7a-41e8-41d3-8b24-2061cb68f2e5",
   "metadata": {},
   "source": [
    "Source: <a href=\"https://huggingface.co/blog/annotated-diffusion\">The Annotated Diffusion Model</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e668f8-2567-455a-82e3-57f4916333d4",
   "metadata": {},
   "source": [
    "## Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac858a8-e011-4a2b-ae7f-7e5198e6611f",
   "metadata": {},
   "source": [
    "### Standardised Convolution and Group Norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a6ff7e-1b0e-43ff-9ee2-e5a90dda9934",
   "metadata": {},
   "source": [
    "When used _Group Normalization_ together with _Weight Standardization_, the performance of model improves and becomes comparable even for small training batch sizes.\n",
    "\n",
    "<a href=\"https://arxiv.org/abs/1803.08494v3\">Group Normalization</a>\n",
    "\n",
    "<a href=\"https://arxiv.org/abs/1903.10520\">Micro-Batch Training with Batch-Channel Normalization and Weight Standardization</a>\n",
    "\n",
    "<a href=\"https://arxiv.org/abs/1912.11370\">Big Transfer (BiT): General Visual Representation Learning</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "460ecde1-70ac-4f88-8735-d4a863284ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WSConv2d(nn.Conv2d):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.eps = 1.e-5\n",
    "    def forward(self, x):\n",
    "        #mean and var are calculated over in_channel and kernel\n",
    "        #note that the mean and var are not detached from autograd\n",
    "        mean = reduce(self.weight, \"o ... -> o 1 1 1\", \"mean\")\n",
    "        std = (reduce(self.weight, \"o ... -> o 1 1 1\", partial(th.var, unbiased=False)) + self.eps).sqrt()\n",
    "        normalized_weight = (self.weight-mean)/std\n",
    "\n",
    "        return F.conv2d(x, normalized_weight, bias=self.bias, stride=self.stride, padding=self.padding, groups=self.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "66974114-8b3a-490f-896a-9983de65783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2dBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size=3, padding=1, groups=8):\n",
    "        super().__init__()\n",
    "        self.conv = WSConv2d(in_channel, out_channel, kernel_size=kernel_size, padding=padding)\n",
    "        self.norm = nn.GroupNorm(groups, out_channel)\n",
    "        self.act = nn.SiLU()\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.norm(x)\n",
    "        return self.act(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c3da02-c97d-4afb-913c-95aea82ef393",
   "metadata": {},
   "source": [
    "### ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ba97da-af12-4c78-9ba0-78ca6ec329f4",
   "metadata": {},
   "source": [
    "Each resnet block consists of two standardized convolutions with a skip connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "b04129cd-3efe-404b-a354-8680771d96c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size=3, padding=1):\n",
    "        super().__init__()\n",
    "        self.resnet_conv = nn.Conv2d(in_channel, out_channel, kernel_size=1, padding=0)\n",
    "        self.conv1 = Conv2dBlock(in_channel, out_channel, kernel_size=kernel_size, padding=padding)\n",
    "        self.conv2 = Conv2dBlock(out_channel, out_channel, kernel_size=kernel_size, padding=padding)\n",
    "    def forward(self, x):\n",
    "        res = self.resnet_conv(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        return x + res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97964b77-537a-429b-b78c-08163348c70c",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e14e3e2-16e3-4ab4-b68d-db8ae6982a9e",
   "metadata": {},
   "source": [
    "For a given batch of images with $C$ channels and $(h,w)$ image dimension, the attention block calculates image whose pixels are attention weighted sum over all pixels. The attention is calculated as follows.\n",
    "\n",
    "The image dimension for each channel is flattented. The attention values are calculated between each query and key pixels with number of channels being the dimension of each pixel. The value pixels are summed weighted by the attention values. The image is unflattened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "a41c0f20-8d1e-4f83-a8ce-bb6129e3551c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, in_channel, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.in_channel = in_channel\n",
    "        self.num_heads = num_heads\n",
    "        self.qkv = nn.Conv2d(self.in_channel, self.in_channel*self.num_heads*3, kernel_size=1)\n",
    "        self.out = nn.Conv2d(self.in_channel*self.num_heads, self.in_channel, kernel_size=1)\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        qkv = self.qkv(x)\n",
    "        qkv = rearrange(qkv, \"b (hd c) h w -> b hd c (h w)\", hd=self.num_heads)\n",
    "        q, k, v = qkv.chunk(3, dim=2)\n",
    "        \n",
    "        scale = 1/math.sqrt(q.shape[-1])\n",
    "        attn = einsum(q, k, \"b hd c d1, b hd c d2 -> b hd d1 d2\")*scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        \n",
    "        out = einsum(attn, v, \"b hd d1 d2, b hd c d2 -> b hd c d1\")\n",
    "        out = rearrange(out, \"b hd c (h1 w1) -> b (hd c) h1 w1\", h1=h, w1=w)\n",
    "        return self.out(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a0a57f-5827-47c1-bd4b-1157e1b21b43",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a0ec3611-ea5a-4a80-b82e-373e3fac5093",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionUNet(nn.Module):\n",
    "    def __init__(self, in_channel, channels):\n",
    "        super().__init__()\n",
    "        self.in_channel = in_channel\n",
    "        self.channels = channels\n",
    "        \n",
    "        self.in_conv = nn.Conv2d(self.in_channel, self.channels[0], kernel_size=3, padding=1)\n",
    "        self.down_stage = nn.ModuleList()\n",
    "        self.mid_stage = nn.ModuleList()\n",
    "        self.up_stage = nn.ModuleList()\n",
    "        self.out_conv = nn.Conv2d(self.channels[1], self.in_channel, kernel_size=3, padding=1)\n",
    "\n",
    "        self.down_channels = list(zip(self.channels[:-2], self.channels[1:-1]))\n",
    "        self.up_channels = list(zip(reversed(self.channels[2:]), reversed(self.channels[1:-1])))\n",
    "\n",
    "        for in_ch, out_ch in self.down_channels:\n",
    "            self.down_stage.append(nn.ModuleList([ResNet(in_ch, out_ch), ResNet(out_ch, out_ch),\n",
    "                                                  Attention(out_ch),\n",
    "                                                  nn.MaxPool2d(kernel_size=2, stride=2)]))\n",
    "        self.mid_stage.append(ResNet(self.channels[-2], self.channels[-1]))\n",
    "        self.mid_stage.append(Attention(self.channels[-1]))\n",
    "        self.mid_stage.append(ResNet(self.channels[-1], self.channels[-1]))\n",
    "\n",
    "        for in_ch, out_ch in self.up_channels:\n",
    "            self.up_stage.append(nn.ModuleList([Upsample(in_ch, out_ch, scale_factor=2),\n",
    "                                                ResNet(in_ch, out_ch), ResNet(out_ch, out_ch),\n",
    "                                                Attention(out_ch)]))\n",
    "    def forward(self, x):\n",
    "        x = self.in_conv(x)\n",
    "        resnet = []\n",
    "        for block1, block2, attn, down in self.down_stage:\n",
    "            x = block1(x)\n",
    "            resnet.append(x)\n",
    "            x = block2(x)\n",
    "            x += attn(x)\n",
    "            x = down(x)\n",
    "        x = self.mid_stage[0](x)\n",
    "        x += self.mid_stage[1](x)\n",
    "        x = self.mid_stage[2](x)\n",
    "\n",
    "        for up, block1, block2, attn in self.up_stage:\n",
    "            x = up(x)\n",
    "            x = th.cat((x, resnet.pop()), dim=1)\n",
    "            x = block1(x)\n",
    "            x = block2(x)\n",
    "            x += attn(x)\n",
    "        x = self.out_conv(x)\n",
    "        return x\n",
    "    @th.no_grad()\n",
    "    def predict(self, x):\n",
    "        return self(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "a944de58-db21-469f-9bf7-df4a8f662771",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channel = 3\n",
    "channels = [32, 64, 128]\n",
    "\n",
    "attn_unet = AttentionUNet(in_channel, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c112484-1838-40a6-9ada-3a1c8ca82b94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
