{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "67b63013-52cf-46a0-a5a2-51851fe9983a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80906b4b-b1ae-4d51-a70f-072610fcfb74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "1d53a5d7-57a1-4671-8c7d-9cfb7d951265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "097507e1-b5a7-4783-afaf-397cbeb244f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from symmetry_model import ScNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "7b88da6b-5227-45d4-89c9-e2ac9ba32596",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfine a sampling subclass of Layer\n",
    "#the Sampling layer takes two inputs: mean and log_sigma\n",
    "#the layer samples random samples from mean and log_sigma assuming that the mean and log_sigma are from from a gaussian distribution\n",
    "class Sampling(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, inputs):\n",
    "        #unpack the inputs\n",
    "        mean, log_var = inputs\n",
    "        batch_size = tf.shape(mean)[0]\n",
    "        #size of the latent layer\n",
    "        units = tf.shape(mean)[1]\n",
    "        #generate random samples from a gaussian distribution of mean=0 and standard deviation=1\n",
    "        epsilon = tf.random.normal(shape=(batch_size, units), mean=0, stddev=1)\n",
    "        #shift and scale epsilon\n",
    "        return mean + tf.math.exp(log_var/2)*epsilon\n",
    "\n",
    "class Encoder(keras.layers.Layer):\n",
    "    def __init__(self, latent_size=1, layer_size=[70, 70], activation='elu', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.layer_size = layer_size\n",
    "        self.latent_size = latent_size\n",
    "        self.encoder_layer = []\n",
    "        for i in range(len(self.layer_size)):\n",
    "            self.encoder_layer.append(Dense(layer_size[i], activation=activation, name=('encoder_layer'+str(i+1))))\n",
    "        self.z = Dense(latent_size, activation=activation, name='latent_layer')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        for i in range(len(self.layer_size)):\n",
    "            x = self.encoder_layer[i](x)\n",
    "        z = self.z(x)\n",
    "        return z\n",
    "\n",
    "class DifferenceSquared(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, inputs):\n",
    "        input1 = inputs[0]\n",
    "        input2 = inputs[1]\n",
    "        mean_squared = tf.reshape(tf.reduce_sum((input1 - input2)**2, axis=1), (-1,1))\n",
    "        return mean_squared\n",
    "\n",
    "#create a subclass VAE of Model\n",
    "#the model takes encoder and decoder models and joins them to build beta-VAE\n",
    "#the model defines a training method to train the beta-VAE model so constructed\n",
    "\"\"\"Variables in the class object:\n",
    "\n",
    "   encoder               --   encoder model to produce mean and log_var as output from the input\n",
    "   decoder               --   decoder model to produce the output\n",
    "   reconstruction_loss   --   total loss for the output accuracy of the decoder - sum over total outputs and average over samples\n",
    "   kl_loss               --   total loss for the kl-metric - sum over output units of latent layer and average over samples\n",
    "   total_loss            --   reconstruction_loss + kl_loss\n",
    "   beta_rec              --   parameter to control the relative significance of reconstruction loss\n",
    "   beta_kl               --   parameter to control the relative significance of kl-divergence loss\n",
    "\"\"\"\n",
    "\n",
    "class ScNN(Model):\n",
    "    def __init__(self, input_size=50, encoder_layer=[70, 70], latent_size=1, output_size=1, beta_rec=500., activation='elu', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = Encoder(layer_size=encoder_layer, latent_size=latent_size, activation=activation, name='encoder')\n",
    "        self.difference_squared = DifferenceSquared(name='comparison_layer')\n",
    "        self.output_classify = Dense(output_size, activation='sigmoid', name='output')\n",
    "        self.beta_rec = beta_rec\n",
    "        #define the losses\n",
    "        #Mean stores the mean value of the argument passed to it and a name for the mean value\n",
    "        self.bce = keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "        self.total_loss = keras.metrics.Mean(name='total_loss')\n",
    "        self.total_reconstruction_loss = keras.metrics.Mean(name='reconstruction_loss')\n",
    "    #return the losses to be printed during training\n",
    "    def build(self, input_shape):\n",
    "        # Add any operations you need to perform during build, like creating weights.\n",
    "        super().build(input_shape)\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.total_loss, self.total_reconstruction_loss]\n",
    "    #feeds an output of encoder and question to the decoder and returns the outputs of encoder and decoder\n",
    "    #encoder input and a question is passed as input\n",
    "    def call(self, inputs):\n",
    "        input1 = inputs[:,0:4]\n",
    "        input2 = inputs[:,4:8]\n",
    "        z1 = self.encoder(input1)\n",
    "        z2 = self.encoder(input2)\n",
    "        decoder_output = self.difference_squared([z1, z2])\n",
    "        \n",
    "        output = self.output_classify(decoder_output)\n",
    "        return output\n",
    "    #training method called when called to fit\n",
    "    #the method is passed a set of observation, a question for each observation and the corresponding answers\n",
    "    def train_step(self, data):\n",
    "        inputs = data['input']\n",
    "        outputs = data['output']\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            #feed-forward step\n",
    "            #calls the call() method\n",
    "            predictions = self(inputs)\n",
    "            #calculate losses for the current feed-forward step\n",
    "            #outputs and predictions are one dimensional so only take mean over samples\n",
    "            #reconstruction_loss = self.beta_rec*tf.reduce_mean(tf.reduce_sum((outputs - predictions)**2, axis=1))\n",
    "            reconstruction_loss = self.beta_rec*self.bce(outputs, predictions)\n",
    "            #take sum over dimension and mean over samples\n",
    "            #kl_loss = 0.5*self.beta_kl*tf.reduce_mean(tf.reduce_sum(tf.square(z_mean) + 2*tf.exp(z_log_sigma) -  2*z_log_sigma, axis=1))\n",
    "            loss = reconstruction_loss\n",
    "            #calculates gradients w.r.t. the trainable weights of the model\n",
    "            gradients = tape.gradient(loss, self.trainable_weights)\n",
    "            #updates the trainable weights using the gradients calculated\n",
    "            #method to update the weights is passed in call to compile function of the model as optimizer parameter\n",
    "            self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "            #updates the current losses\n",
    "            self.total_reconstruction_loss.update_state(reconstruction_loss)\n",
    "            self.total_loss.update_state(loss)\n",
    "            #return the losses name and the corresponding values\n",
    "            return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794e629c-1595-4232-8aa0-dd8905e42fa7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "7518327d-1db1-45d7-8010-1f17b0de06d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate3DRotations(num=1):\n",
    "    vector_dimension = 4\n",
    "    random_3drotation = np.zeros((num, vector_dimension, vector_dimension))\n",
    "    random_3drotation[:, 1:,1:] = scipy.spatial.transform.Rotation.random(train_samples).as_matrix()\n",
    "    random_3drotation[:,0,0] = 1\n",
    "    return random_3drotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "a2c47478-09e7-47fa-834c-c200860224f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateLorentzTransforms(num=1):\n",
    "    vector_dimension = 4\n",
    "    beta = np.random.uniform(low=0, high=0.99, size=(train_samples, 1,1))\n",
    "    gamma = 1/np.sqrt(1-beta**2)\n",
    "    random_lorentz_trans = np.zeros((train_samples, vector_dimension, vector_dimension))\n",
    "    random_lorentz_trans[:, 0:1, 1] = beta[:,0:1,0]\n",
    "    random_lorentz_trans[:, 1:2, 0] = beta[:,0:1,0]\n",
    "    random_lorentz_trans[:, 0, 0] = 1\n",
    "    random_lorentz_trans[:, 1, 1] = 1\n",
    "    random_lorentz_trans = random_lorentz_trans*gamma\n",
    "    random_lorentz_trans[:, 2, 2] = 1\n",
    "    random_lorentz_trans[:, 3, 3] = 1\n",
    "    return random_lorentz_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "1c64e6d0-cce2-4050-b51f-4a180f2e5ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateInterval(event):\n",
    "    vector_dimension = event.shape[1]\n",
    "    interval = event[:,0:1]**2\n",
    "    for i in range(1, vector_dimension):\n",
    "        interval -= event[:,i:i+1]**2\n",
    "    return interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "bdfe626c-1c05-4756-8065-87ac1430e238",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = 50000\n",
    "vector_dimension = 4\n",
    "\n",
    "random_3drotation1 = generate3DRotations(num=train_samples)\n",
    "random_3drotation2 = generate3DRotations(num=train_samples)\n",
    "\n",
    "random_lorentz_trans = generateLorentzTransforms(num=train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "3a6afea0-ae3e-4a98-ac28-b6387e297577",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_lorentz_trans = np.matmul(np.matmul(random_3drotation1, random_lorentz_trans), random_3drotation2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "401d9f1c-cd9f-4dae-abc3-1e3dc1b91509",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_train = np.random.uniform(low=-1, high=1, size=(train_samples, vector_dimension, 1))\n",
    "events_similar_train = np.matmul(random_lorentz_trans, events_train)\n",
    "\n",
    "#the third index does not store any extra dimension\n",
    "events_train = events_train[:,:,0]\n",
    "events_similar_train = events_similar_train[:,:,0]\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "events_asimilar_train = rng.permutation(events_similar_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "a87f1eee-05a6-4cce-8cd0-5924d462f159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "events_train.shape: (100000, 4)\n",
      "transformed_events.shape: (100000, 4)\n",
      "labels.shape: (100000, 1)\n"
     ]
    }
   ],
   "source": [
    "events_train = np.row_stack((events_train, events_train))\n",
    "print('events_train.shape: '+str(events_train.shape))\n",
    "\n",
    "transformed_events = np.row_stack((events_similar_train, events_asimilar_train))\n",
    "print('transformed_events.shape: '+str(transformed_events.shape))\n",
    "\n",
    "true_label = np.zeros((train_samples,1))\n",
    "false_label = np.ones((train_samples,1))\n",
    "labels = np.row_stack((true_label, false_label))\n",
    "print('labels.shape: '+str(labels.shape))\n",
    "\n",
    "event_pairs_and_similar_label = np.column_stack((events_train, transformed_events, labels))\n",
    "event_pairs_and_similar_label = rng.permutation(event_pairs_and_similar_label, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "2af551ab-8bdc-467a-882d-53cadc49b0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval1 = calculateInterval(event_pairs_and_similar_label[:,:4])\n",
    "interval2 = calculateInterval(event_pairs_and_similar_label[:,4:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "547dc054-abf8-48af-b988-afd036a44bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.70676288 -0.85369407 -0.17025569 -0.80262543 -0.97369181 -0.15977353\n",
      "  -0.84187347 -0.85602873 -1.0418498  -0.11697056 -0.43526787 -0.55669337\n",
      "  -1.29500094 -1.22813809 -0.93855722 -0.99593009  0.66204229 -0.61555704\n",
      "   0.23628257 -0.87764698]]\n",
      "[[ 0.04318917 -0.96906135 -0.45494832 -0.80262543 -0.97369181 -0.15977353\n",
      "   0.77589974 -0.85602873 -1.34542064 -0.11697056 -0.24783517 -0.55669337\n",
      "  -1.29500094 -1.22813809 -6.30546965 -0.99593009 -1.97414375 -0.61555704\n",
      "  -2.60386625 -0.87764698]]\n",
      "[1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(interval1[:20].T)\n",
    "print(interval2[:20].T)\n",
    "print(event_pairs_and_similar_label[:20,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c390de-2cd7-4e06-987b-a3b436405670",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "a6b46950-381e-45d9-941a-f1bdcaa77691",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_size=50, encoder_layer=[70, 70], latent_size=3, output_size=1, beta_rec=500., beta_kl=1.\n",
    "beta_rec = 500\n",
    "\n",
    "model = ScNN(input_size=8, encoder_layer=[150,150], latent_size=1, output_size=1, beta_rec=beta_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "75dd740d-c95d-459e-bcd7-0ef6e428318d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - reconstruction_loss: 4615801490450153472.0000 - total_loss: 4615801490450153472.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - reconstruction_loss: 1268.2445 - total_loss: 1268.2445\n",
      "Epoch 3/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - reconstruction_loss: 1944.7305 - total_loss: 1944.7305\n",
      "Epoch 4/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - reconstruction_loss: 1585.7946 - total_loss: 1585.7946\n",
      "Epoch 5/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - reconstruction_loss: 2534.1201 - total_loss: 2534.1201\n",
      "Epoch 6/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - reconstruction_loss: 1445.7617 - total_loss: 1445.7617\n",
      "Epoch 7/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - reconstruction_loss: 2177.3540 - total_loss: 2177.3540\n",
      "Epoch 8/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - reconstruction_loss: 2376.1306 - total_loss: 2376.1306\n",
      "Epoch 9/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - reconstruction_loss: 712.1015 - total_loss: 712.1015\n",
      "Epoch 10/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - reconstruction_loss: 2226.3723 - total_loss: 2226.3723\n",
      "Epoch 11/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - reconstruction_loss: 2263.5671 - total_loss: 2263.5671\n",
      "Epoch 12/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - reconstruction_loss: 3402.4109 - total_loss: 3402.4109\n",
      "Epoch 13/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - reconstruction_loss: 913.7056 - total_loss: 913.7056\n",
      "Epoch 14/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - reconstruction_loss: 2594.3162 - total_loss: 2594.3162\n",
      "Epoch 15/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - reconstruction_loss: 2234.9407 - total_loss: 2234.9407\n",
      "Epoch 16/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - reconstruction_loss: 1710.9692 - total_loss: 1710.9692\n",
      "Epoch 17/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - reconstruction_loss: 1075.2208 - total_loss: 1075.2208\n",
      "Epoch 18/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - reconstruction_loss: 1913.5560 - total_loss: 1913.5560\n",
      "Epoch 19/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - reconstruction_loss: 3186.9443 - total_loss: 3186.9443\n",
      "Epoch 20/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - reconstruction_loss: 1457.7528 - total_loss: 1457.7528\n",
      "Epoch 21/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - reconstruction_loss: 2088.7434 - total_loss: 2088.7434\n",
      "Epoch 22/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - reconstruction_loss: 1419.0720 - total_loss: 1419.0720\n",
      "Epoch 23/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - reconstruction_loss: 3121.2136 - total_loss: 3121.2136\n",
      "Epoch 24/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - reconstruction_loss: 1370.7556 - total_loss: 1370.7556\n",
      "Epoch 25/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - reconstruction_loss: 1692.0233 - total_loss: 1692.0233\n",
      "Epoch 26/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - reconstruction_loss: 1199.3496 - total_loss: 1199.3496\n",
      "Epoch 27/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - reconstruction_loss: 970.2184 - total_loss: 970.2184\n",
      "Epoch 28/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - reconstruction_loss: 1363.1920 - total_loss: 1363.1920\n",
      "Epoch 29/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - reconstruction_loss: 2493.5791 - total_loss: 2493.5791\n",
      "Epoch 30/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - reconstruction_loss: 1953.1639 - total_loss: 1953.1639\n",
      "Epoch 31/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - reconstruction_loss: 1277.6072 - total_loss: 1277.6072\n",
      "Epoch 32/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - reconstruction_loss: 1953.6063 - total_loss: 1953.6063\n",
      "Epoch 33/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - reconstruction_loss: 2331.1289 - total_loss: 2331.1289\n",
      "Epoch 34/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - reconstruction_loss: 1604.4000 - total_loss: 1604.4000\n",
      "Epoch 35/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - reconstruction_loss: 1204.5607 - total_loss: 1204.5607\n",
      "Epoch 36/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - reconstruction_loss: 1261.4551 - total_loss: 1261.4551\n",
      "Epoch 37/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - reconstruction_loss: 1862.6254 - total_loss: 1862.6254\n",
      "Epoch 38/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - reconstruction_loss: 1214.7722 - total_loss: 1214.7722\n",
      "Epoch 39/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - reconstruction_loss: 1159.8662 - total_loss: 1159.8662\n",
      "Epoch 40/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - reconstruction_loss: 2146.7930 - total_loss: 2146.7930\n",
      "Epoch 41/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - reconstruction_loss: 1516.2031 - total_loss: 1516.2031\n",
      "Epoch 42/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - reconstruction_loss: 2086.6208 - total_loss: 2086.6208\n",
      "Epoch 43/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - reconstruction_loss: 3266.4785 - total_loss: 3266.4785\n",
      "Epoch 44/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - reconstruction_loss: 2059.3826 - total_loss: 2059.3826\n",
      "Epoch 45/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - reconstruction_loss: 945.8768 - total_loss: 945.8768 \n",
      "Epoch 46/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - reconstruction_loss: 1499.8988 - total_loss: 1499.8988\n",
      "Epoch 47/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - reconstruction_loss: 1632.6479 - total_loss: 1632.6479\n",
      "Epoch 48/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - reconstruction_loss: 911.6605 - total_loss: 911.6605\n",
      "Epoch 49/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - reconstruction_loss: 2473.3987 - total_loss: 2473.3987\n",
      "Epoch 50/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - reconstruction_loss: 1439.2443 - total_loss: 1439.2443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f3844866d50>"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 50\n",
    "batch_size = 500\n",
    "learning_rate = 100.\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate))\n",
    "model.fit({'input': event_pairs_and_similar_label[:, :-1], 'output': event_pairs_and_similar_label[:,-1].reshape(-1,1)}, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "412a7672-647b-4f92-9fe0-be8bf137dc56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f383f906720>"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAGdCAYAAAAfTAk2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAjtklEQVR4nO3df1DUdeLH8deCuIDKkiK/ioRTD7LUURsVpk4ukzA1rRvL7Di9UcdszKG6M60raRo1nNLmzsprplOv666mjOrGjq/cKFYjqHRw/ijRUwsTVzNxISNQeH//8NwTQWSR5cfb52NmZ24/+34v7/d9LvbZhw+cwxhjBAAAYJGAjl4AAABAWyNwAACAdQgcAABgHQIHAABYh8ABAADWIXAAAIB1CBwAAGAdAgcAAFinW0cvoCPU19ervLxcvXr1ksPh6OjlAACAFjDGqKqqSrGxsQoIaP4azTUZOOXl5YqLi+voZQAAgFY4cuSIbrjhhmbHXJOB06tXL0nn/wsKCwvr4NUAAICWqKysVFxcnPdzvDnXZOBc+LFUWFgYgQMAQBfTkttLuMkYAABYh8ABAADWIXAAAIB1CBwAAGAdAgcAAFiHwAEAANYhcAAAgHUIHAAAYB0CBwAAWIfAAQAA1iFwAACAdQgcAABgHQIHAABYh8ABAADWIXAAAIB1CBwAAGAdAgcAAFiHwAEAANYhcAAAgHUIHAAAYB0CBwAAWIfAAQAA1iFwAACAdQgcAABgHQIHAABYh8ABAADWIXAAAIB1CBwAAGAdAgcAAFiHwAEAANYhcAAAgHUIHAAAYB0CBwAAWIfAAQAA1iFwAACAdQgcAABgHQIHAABYh8ABAADWIXAAAIB1CBwAAGAdAgcAAFiHwAEAANYhcAAAgHX8GjgVFRXKyMiQy+WSy+VSRkaGTp8+3eyc48ePa+bMmYqNjVVoaKjS09N14MCBRuMKCgp0xx13qEePHgoPD1dqaqqqq6v9tBMAANCV+DVwpk+frpKSEuXm5io3N1clJSXKyMi47HhjjKZMmaJDhw7pww8/VHFxsfr166c777xTZ86c8Y4rKChQenq60tLStGPHDu3cuVPz589XQAAXpAAAgOQwxhh/vPGXX36pQYMGqbCwUKNGjZIkFRYWKjk5Wfv27VNiYmKjOfv371diYqL27Nmjm2++WZJUV1enyMhIZWdna/bs2ZKk0aNHa9y4cXr++edbtbbKykq5XC55PB6FhYW1cocAAKA9+fL57bdLHgUFBXK5XN64kc6Hicvl0rZt25qcU1NTI0kKDg72HgsMDFT37t312WefSZJOnDih7du3KzIyUikpKYqKitKYMWO8r1/ufSsrKxs8AACAvfwWOG63W5GRkY2OR0ZGyu12NzknKSlJ/fr10+LFi1VRUaHa2lq98MILcrvdOnbsmCTp0KFDkqSsrCzNmTNHubm5Gj58uMaOHdvkvTqStHz5cu99QC6XS3FxcW20SwAA0Bn5HDhZWVlyOBzNPoqKiiRJDoej0XxjTJPHJSkoKEgbNmzQ/v371bt3b4WGhio/P1/jx49XYGCgJKm+vl6SNHfuXP3617/WsGHDtGrVKiUmJupPf/pTk++7ePFieTwe7+PIkSO+bhsAAHQh3XydMH/+fE2bNq3ZMfHx8dq1a5eOHz/e6LVvv/1WUVFRl507YsQIlZSUyOPxqLa2Vn379tWoUaN06623SpJiYmIkSYMGDWow76abblJZWVmT7+l0OuV0OptdMwAAsIfPgRMREaGIiIgrjktOTpbH49GOHTs0cuRISdL27dvl8XiUkpJyxfkul0uSdODAARUVFXlvKI6Pj1dsbKxKS0sbjN+/f7/Gjx/v63YAAICF/HYPzk033aT09HTNmTNHhYWFKiws1Jw5czRx4sQGv0GVlJSknJwc7/N3331X+fn53l8VHzdunKZMmaK0tDRJ53/s9dvf/la///3v9d577+k///mPnnnmGe3bt0+zZs3y13YAAEAX4vMVHF+89dZbWrBggTdO7rnnHq1evbrBmNLSUnk8Hu/zY8eO6fHHH9fx48cVExOjX/3qV3rmmWcazMnMzNSPP/6oxx57TKdOndLQoUOVl5en/v37+3M7AACgi/Db38HpzPg7OAAAdD2d4u/gAAAAdBQCBwAAWIfAAQAA1iFwAACAdQgcAABgHQIHAABYh8ABAADWIXAAAIB1CBwAAGAdAgcAAFiHwAEAANYhcAAAgHUIHAAAYB0CBwAAWIfAAQAA1iFwAACAdQgcAABgHQIHAABYh8ABAADWIXAAAIB1CBwAAGAdAgcAAFiHwAEAANYhcAAAgHUIHAAAYB0CBwAAWIfAAQAA1iFwAACAdQgcAABgHQIHAABYh8ABAADWIXAAAIB1CBwAAGAdAgcAAFiHwAEAANYhcAAAgHUIHAAAYB0CBwAAWIfAAQAA1iFwAACAdQgcAABgHQIHAABYh8ABAADWIXAAAIB1CBwAAGAdAgcAAFiHwAEAANYhcAAAgHUIHAAAYB0CBwAAWIfAAQAA1iFwAACAdQgcAABgHQIHAABYh8ABAADWIXAAAIB1/Bo4FRUVysjIkMvlksvlUkZGhk6fPt3snOPHj2vmzJmKjY1VaGio0tPTdeDAgQZj3G63MjIyFB0drR49emj48OF67733/LgTAADQlfg1cKZPn66SkhLl5uYqNzdXJSUlysjIuOx4Y4ymTJmiQ4cO6cMPP1RxcbH69eunO++8U2fOnPGOy8jIUGlpqT766CPt3r1b9913nx544AEVFxf7czsAAKCLcBhjjD/e+Msvv9SgQYNUWFioUaNGSZIKCwuVnJysffv2KTExsdGc/fv3KzExUXv27NHNN98sSaqrq1NkZKSys7M1e/ZsSVLPnj312muvNYilPn36aMWKFZo1a9YV11ZZWSmXyyWPx6OwsLC22C4AAPAzXz6//XYFp6CgQC6Xyxs3kjR69Gi5XC5t27atyTk1NTWSpODgYO+xwMBAde/eXZ999pn32G233aZ33nlHp06dUn19vd5++23V1NQoNTX1su9bWVnZ4AEAAOzlt8Bxu92KjIxsdDwyMlJut7vJOUlJSerXr58WL16siooK1dbW6oUXXpDb7daxY8e849555x2dO3dOffr0kdPp1Ny5c5WTk6P+/fs3+b7Lly/33gfkcrkUFxfXNpsEAACdks+Bk5WVJYfD0eyjqKhIkuRwOBrNN8Y0eVySgoKCtGHDBu3fv1+9e/dWaGio8vPzNX78eAUGBnrH/e53v1NFRYX++c9/qqioSI8//rimTp2q3bt3N/m+ixcvlsfj8T6OHDni67YBAEAX0s3XCfPnz9e0adOaHRMfH69du3bp+PHjjV779ttvFRUVddm5I0aMUElJiTwej2pra9W3b1+NGjVKt956qyTp4MGDWr16dYP7dIYOHapPP/1Ur7zyitasWdPoPZ1Op5xOpy/bBAAAXZjPgRMREaGIiIgrjktOTpbH49GOHTs0cuRISdL27dvl8XiUkpJyxfkul0uSdODAARUVFen555+XJP3www+SpICAhhefAgMDVV9f79NeAACAnfx2D85NN92k9PR0zZkzR4WFhSosLNScOXM0ceLEBr9BlZSUpJycHO/zd999V/n5+d5fFR83bpymTJmitLQ07/gBAwZo7ty52rFjhw4ePKiXXnpJeXl5mjJlir+2AwAAuhC//h2ct956S4MHD1ZaWprS0tI0ZMgQvfnmmw3GlJaWyuPxeJ8fO3ZMGRkZSkpK0oIFC5SRkaG//e1v3teDgoL08ccfq2/fvpo0aZKGDBmiP//5z1q/fr3uvvtuf24HAAB0EX77OzidGX8HBwCArqdT/B0cAACAjkLgAAAA6xA4AADAOgQOAACwDoEDAACsQ+AAAADrEDgAAMA6BA4AALAOgQMAAKxD4AAAAOsQOAAAwDoEDgAAsA6BAwAArEPgAAAA6xA4AADAOgQOAACwDoEDAACsQ+AAAADrEDgAAMA6BA4AALAOgQMAAKxD4AAAAOsQOAAAwDoEDgAAsA6BAwAArEPgAAAA6xA4AADAOgQOAACwDoEDAACsQ+AAAADrEDgAAMA6BA4AALAOgQMAAKxD4AAAAOsQOAAAwDoEDgAAsA6BAwAArEPgAAAA6xA4AADAOgQOAACwDoEDAACsQ+AAAADrEDgAAMA6BA4AALAOgQMAAKxD4AAAAOsQOAAAwDoEDgAAsA6BAwAArEPgAAAA6xA4AADAOgQOAACwDoEDAACsQ+AAAADrEDgAAMA6BA4AALCOXwNn6dKlSklJUWhoqMLDw1s0xxijrKwsxcbGKiQkRKmpqdq7d2+DMTU1NXr00UcVERGhHj166J577tE333zjhx0AAICuyK+BU1tbq6lTp2revHktnrNixQqtXLlSq1ev1s6dOxUdHa1x48apqqrKOyYzM1M5OTl6++239dlnn+n777/XxIkTVVdX549tAACALsZhjDH+/iLr1q1TZmamTp8+3ew4Y4xiY2OVmZmpJ598UtL5qzVRUVHKzs7W3Llz5fF41LdvX7355pt64IEHJEnl5eWKi4vTxx9/rLvuuuuK66msrJTL5ZLH41FYWNhV7w8AAPifL5/f3dppTS1y+PBhud1upaWleY85nU6NGTNG27Zt09y5c/X555/r7NmzDcbExsbqlltu0bZt25oMnJqaGtXU1HifV1ZW+m0Pfyn8Wks3fqEfz9Zr0tBYjUzordfyD2pean/9cnQ//aXwa72Wf1Aj+l2nz7+u8B5v6n0unffi/5VKkn5zV2KTcy7Me/H/SlVzrk7OboH6zV2JkuSd+7Of9tXnX1doRL/r9Mn+b1Vzrk7n6ozO1RsNvt6l787UNljTgr8V6+//Lle3AId6OLvpxt6h2n3Uo+CgAI0bFK28L9yqPlvv/fpBAQ51CwxQzbk61f83na8PD9aZmjqdqT2ns3Xmv2McqjlXr3ojOSRdrrIDHPK+z8WCAhzq4QzU6epzLTgrAGC/pr5fXvz9dcj1LsVH9NBH/y6XdOH76Pnv63vLPZowJFa/f3CYd+6CvxVr465y3Rx7/rOhT4/uDcY193l26WdYR+hUNxm73W5JUlRUVIPjUVFR3tfcbre6d++u66677rJjLrV8+XK5XC7vIy4uzg+rP++1/IOqPlsvI2njrnK9ln9QR09X67X8g97Xj56u1sZd5Q2ON/U+l847XX1Wp6vPXnbOxeOqz9Z7x14898LX3bir3DvubL2RkbTrqKfRmjbuKpeRdLbe6HT1We066pGRVH22Xht3lTeIG/13XPXZugb/kB09/aNOV5/V2Tpz0Zh675jmLiE2FTcX3oO4AYD/aer75cWHdh31aOOucu/zi7+v1xk1eE06/7zO/O+z4dJxzX2eXfoZ1hF8DpysrCw5HI5mH0VFRVe1KIfD0eC5MabRsUs1N2bx4sXyeDzex5EjR65qfc2Zl9pfIUEBckiaMCRW81L76/rwEM1L7e99/frwEE0YEtvgeFPvc+m88JAghYcEXXbOxeNCggK8Yy+ee+HrThgS6x0XFOCQQ+fr/tI1TRgSK4fOl354SJCGXO+SQ1JIUIAmDIlVSFDD/wkFBTgUEhSogItOxfXhwQoPCVJQoOOiMQHeMc2d2YDLvHh+PZ3qAiQAdKimvl9efGjI9S5NGBLrfX7x9/VAhxq8Jp1/Huj432fDpeOa+zy79DOsI/h8D87Jkyd18uTJZsfEx8crODjY+7yl9+AcOnRI/fv317/+9S8NG/a/y2STJ09WeHi41q9fr82bN2vs2LE6depUg6s4Q4cO1ZQpU/Tcc89dcQ/cgwMAQNfj13twIiIiFBER0erFNSchIUHR0dHKy8vzBk5tba22bt2q7OxsSdKIESMUFBSkvLw83X///ZKkY8eOac+ePVqxYoVf1gUAALoWv17jLysr06lTp1RWVqa6ujqVlJRIkgYMGKCePXtKkpKSkrR8+XLde++9cjgcyszM1LJlyzRw4EANHDhQy5YtU2hoqKZPny5JcrlcmjVrlp544gn16dNHvXv31m9+8xsNHjxYd955pz+3AwAAugi/Bs6zzz6r9evXe59fuCqzZcsWpaamSpJKS0vl8Xi8YxYuXKjq6mo98sgjqqio0KhRo7Rp0yb16tXLO2bVqlXq1q2b7r//flVXV2vs2LFat26dAgMD/bkdAADQRbTL38HpbLgHBwCArseXz+9O9WviAAAAbYHAAQAA1iFwAACAdQgcAABgHQIHAABYh8ABAADWIXAAAIB1CBwAAGAdAgcAAFiHwAEAANYhcAAAgHUIHAAAYB0CBwAAWIfAAQAA1iFwAACAdQgcAABgHQIHAABYh8ABAADWIXAAAIB1CBwAAGAdAgcAAFiHwAEAANYhcAAAgHUIHAAAYB0CBwAAWIfAAQAA1iFwAACAdQgcAABgHQIHAABYh8ABAADWIXAAAIB1CBwAAGAdAgcAAFiHwAEAANYhcAAAgHUIHAAAYB0CBwAAWIfAAQAA1iFwAACAdQgcAABgHQIHAABYh8ABAADWIXAAAIB1CBwAAGAdAgcAAFiHwAEAANYhcAAAgHUIHAAAYB0CBwAAWIfAAQAA1iFwAACAdQgcAABgHQIHAABYh8ABAADWIXAAAIB1CBwAAGAdAgcAAFjHr4GzdOlSpaSkKDQ0VOHh4S2aY4xRVlaWYmNjFRISotTUVO3du9f7+qlTp/Too48qMTFRoaGhuvHGG7VgwQJ5PB4/7QIAAHQ1fg2c2tpaTZ06VfPmzWvxnBUrVmjlypVavXq1du7cqejoaI0bN05VVVWSpPLycpWXl+vFF1/U7t27tW7dOuXm5mrWrFn+2gYAAOhiHMYY4+8vsm7dOmVmZur06dPNjjPGKDY2VpmZmXryySclSTU1NYqKilJ2drbmzp3b5Lx3331Xv/zlL3XmzBl169btiuuprKyUy+WSx+NRWFiYz/sBAADtz5fP7051D87hw4fldruVlpbmPeZ0OjVmzBht27btsvMubPRycVNTU6PKysoGDwAAYK9OFThut1uSFBUV1eB4VFSU97VLfffdd3r++ecve3VHkpYvXy6Xy+V9xMXFtd2iAQBAp+Nz4GRlZcnhcDT7KCoquqpFORyOBs+NMY2OSecvVU2YMEGDBg3SkiVLLvt+ixcvlsfj8T6OHDlyVesDAACd25VvWLnE/PnzNW3atGbHxMfHt2ox0dHRks5fyYmJifEeP3HiRKOrOlVVVUpPT1fPnj2Vk5OjoKCgy76v0+mU0+ls1ZoAAEDX43PgREREKCIiwh9rUUJCgqKjo5WXl6dhw4ZJOv+bWFu3blV2drZ3XGVlpe666y45nU599NFHCg4O9st6AABA1+TXe3DKyspUUlKisrIy1dXVqaSkRCUlJfr++++9Y5KSkpSTkyPp/I+mMjMztWzZMuXk5GjPnj2aOXOmQkNDNX36dEnnr9ykpaXpzJkzeuONN1RZWSm32y232626ujp/bgcAAHQRPl/B8cWzzz6r9evXe59fuCqzZcsWpaamSpJKS0sb/JG+hQsXqrq6Wo888ogqKio0atQobdq0Sb169ZIkff7559q+fbskacCAAQ2+3uHDh1v94zEAAGCPdvk7OJ0NfwcHAICup8v+HRwAAIC2QOAAAADrEDgAAMA6BA4AALAOgQMAAKxD4AAAAOsQOAAAwDoEDgAAsA6BAwAArEPgAAAA6xA4AADAOgQOAACwDoEDAACsQ+AAAADrEDgAAMA6BA4AALAOgQMAAKxD4AAAAOsQOAAAwDoEDgAAsA6BAwAArEPgAAAA6xA4AADAOgQOAACwDoEDAACsQ+AAAADrEDgAAMA6BA4AALAOgQMAAKxD4AAAAOsQOAAAwDoEDgAAsA6BAwAArEPgAAAA6xA4AADAOgQOAACwDoEDAACsQ+AAAADrEDgAAMA6BA4AALAOgQMAAKxD4AAAAOsQOAAAwDoEDgAAsA6BAwAArEPgAAAA6xA4AADAOgQOAACwDoEDAACsQ+AAAADrEDgAAMA6BA4AALAOgQMAAKxD4AAAAOsQOAAAwDoEDgAAsI5fA2fp0qVKSUlRaGiowsPDWzTHGKOsrCzFxsYqJCREqamp2rt372XHjh8/Xg6HQx988EHbLRwAAHRpfg2c2tpaTZ06VfPmzWvxnBUrVmjlypVavXq1du7cqejoaI0bN05VVVWNxr788styOBxtuWQAAGCBbv588+eee06StG7duhaNN8bo5Zdf1tNPP6377rtPkrR+/XpFRUXpr3/9q+bOnesd++9//1srV67Uzp07FRMT0+ZrBwAAXVenugfn8OHDcrvdSktL8x5zOp0aM2aMtm3b5j32ww8/6MEHH9Tq1asVHR19xfetqalRZWVlgwcAALBXpwoct9stSYqKimpwPCoqyvuaJD322GNKSUnR5MmTW/S+y5cvl8vl8j7i4uLabtEAAKDT8TlwsrKy5HA4mn0UFRVd1aIuva/GGOM99tFHH2nz5s16+eWXW/x+ixcvlsfj8T6OHDlyVesDAACdm8/34MyfP1/Tpk1rdkx8fHyrFnPhx01ut7vBfTUnTpzwXtXZvHmzDh482Oi3sn7xi1/o9ttvV35+fqP3dTqdcjqdrVoTAADoenwOnIiICEVERPhjLUpISFB0dLTy8vI0bNgwSed/E2vr1q3Kzs6WJC1atEizZ89uMG/w4MFatWqVJk2a5Jd1AQCArsWvv0VVVlamU6dOqaysTHV1dSopKZEkDRgwQD179pQkJSUlafny5br33nvlcDiUmZmpZcuWaeDAgRo4cKCWLVum0NBQTZ8+XdL5qzxN3Vh84403KiEhwZ/bAQAAXYRfA+fZZ5/V+vXrvc8vXJXZsmWLUlNTJUmlpaXyeDzeMQsXLlR1dbUeeeQRVVRUaNSoUdq0aZN69erlz6UCAACLOIwxpqMX0d4qKyvlcrnk8XgUFhbW0csBAAAt4Mvnd6f6NXEAAIC2QOAAAADrEDgAAMA6BA4AALAOgQMAAKxD4AAAAOsQOAAAwDoEDgAAsA6BAwAArEPgAAAA6xA4AADAOgQOAACwDoEDAACsQ+AAAADrEDgAAMA6BA4AALAOgQMAAKxD4AAAAOsQOAAAwDoEDgAAsA6BAwAArEPgAAAA6xA4AADAOgQOAACwDoEDAACsQ+AAAADrEDgAAMA6BA4AALAOgQMAAKxD4AAAAOsQOAAAwDoEDgAAsA6BAwAArEPgAAAA6xA4AADAOgQOAACwDoEDAACsQ+AAAADrEDgAAMA6BA4AALAOgQMAAKxD4AAAAOt06+gFdARjjCSpsrKyg1cCAABa6sLn9oXP8eZck4FTVVUlSYqLi+vglQAAAF9VVVXJ5XI1O8ZhWpJBlqmvr1d5ebl69eolh8PR0ctpkcrKSsXFxenIkSMKCwvr6OW0G/Z9be1bunb3zr7Z97XiavZujFFVVZViY2MVEND8XTbX5BWcgIAA3XDDDR29jFYJCwu75v5hkNj3teha3Tv7vrZcq/uWWr/3K125uYCbjAEAgHUIHAAAYB0Cp4twOp1asmSJnE5nRy+lXbHva2vf0rW7d/bNvq8V7bX3a/ImYwAAYDeu4AAAAOsQOAAAwDoEDgAAsA6BAwAArEPgdFJfffWVZs2apYSEBIWEhKh///5asmSJamtrm503c+ZMORyOBo/Ro0e306qvXmv3bYxRVlaWYmNjFRISotTUVO3du7edVt02li5dqpSUFIWGhio8PLxFc7r6+ZZat28bzrckVVRUKCMjQy6XSy6XSxkZGTp9+nSzc7riOX/11VeVkJCg4OBgjRgxQp9++mmz47du3aoRI0YoODhYP/nJT7RmzZp2Wmnb8mXf+fn5jc6rw+HQvn372nHFV++TTz7RpEmTFBsbK4fDoQ8++OCKc/x1vgmcTmrfvn2qr6/XH//4R+3du1erVq3SmjVr9NRTT11xbnp6uo4dO+Z9fPzxx+2w4rbR2n2vWLFCK1eu1OrVq7Vz505FR0dr3Lhx3v/fsa6gtrZWU6dO1bx583ya15XPt9S6fdtwviVp+vTpKikpUW5urnJzc1VSUqKMjIwrzutK5/ydd95RZmamnn76aRUXF+v222/X+PHjVVZW1uT4w4cP6+6779btt9+u4uJiPfXUU1qwYIE2bNjQziu/Or7u+4LS0tIG53bgwIHttOK2cebMGQ0dOlSrV69u0Xi/nm+DLmPFihUmISGh2TEzZswwkydPbp8FtZMr7bu+vt5ER0ebF154wXvsxx9/NC6Xy6xZs6Y9ltim1q5da1wuV4vG2nS+W7pvW873F198YSSZwsJC77GCggIjyezbt++y87raOR85cqR5+OGHGxxLSkoyixYtanL8woULTVJSUoNjc+fONaNHj/bbGv3B131v2bLFSDIVFRXtsLr2Icnk5OQ0O8af55srOF2Ix+NR7969rzguPz9fkZGR+ulPf6o5c+boxIkT7bA6/7nSvg8fPiy32620tDTvMafTqTFjxmjbtm3tscQOZdv5vhJbzndBQYFcLpdGjRrlPTZ69Gi5XK4r7qOrnPPa2lp9/vnnDc6VJKWlpV12jwUFBY3G33XXXSoqKtLZs2f9tta21Jp9XzBs2DDFxMRo7Nix2rJliz+X2Sn483wTOF3EwYMH9Yc//EEPP/xws+PGjx+vt956S5s3b9ZLL72knTt36o477lBNTU07rbRttWTfbrdbkhQVFdXgeFRUlPc1W9l2vlvClvPtdrsVGRnZ6HhkZGSz++hK5/zkyZOqq6vz6Vy53e4mx587d04nT57021rbUmv2HRMTo9dff10bNmzQ+++/r8TERI0dO1affPJJeyy5w/jzfBM47SwrK6vJG8kufhQVFTWYU15ervT0dE2dOlWzZ89u9v0feOABTZgwQbfccosmTZqkf/zjH9q/f782btzoz21dkb/3LUkOh6PBc2NMo2PtrTX79oVN59tXnfF8S77tvan1XmkfnfWcN8fXc9XU+KaOd3a+7DsxMVFz5szR8OHDlZycrFdffVUTJkzQiy++2B5L7VD+Ot/drmo2fDZ//nxNmzat2THx8fHe/1xeXq6f//znSk5O1uuvv+7z14uJiVG/fv104MABn+e2JX/uOzo6WtL5fxOIiYnxHj9x4kSjfzNob77u+2p11fPti858vqWW733Xrl06fvx4o9e+/fZbn/bRWc55UyIiIhQYGNjoqkVz5yo6OrrJ8d26dVOfPn38tta21Jp9N2X06NH6y1/+0tbL61T8eb4JnHYWERGhiIiIFo09evSofv7zn2vEiBFau3atAgJ8v+D23Xff6ciRIw0+CDqCP/edkJCg6Oho5eXladiwYZLO/wx869atys7Ovuq1Xw1f9t0WuuL59lVnPt9Sy/eenJwsj8ejHTt2aOTIkZKk7du3y+PxKCUlpcVfr7Oc86Z0795dI0aMUF5enu69917v8by8PE2ePLnJOcnJyfr73//e4NimTZt06623KigoyK/rbSut2XdTiouLO+V5bUt+Pd9XfZsy/OLo0aNmwIAB5o477jDffPONOXbsmPdxscTERPP+++8bY4ypqqoyTzzxhNm2bZs5fPiw2bJli0lOTjbXX3+9qays7Iht+Kw1+zbGmBdeeMG4XC7z/vvvm927d5sHH3zQxMTEdJl9G2PM119/bYqLi81zzz1nevbsaYqLi01xcbGpqqryjrHtfBvj+76NseN8G2NMenq6GTJkiCkoKDAFBQVm8ODBZuLEiQ3GdPVz/vbbb5ugoCDzxhtvmC+++MJkZmaaHj16mK+++soYY8yiRYtMRkaGd/yhQ4dMaGioeeyxx8wXX3xh3njjDRMUFGTee++9jtpCq/i671WrVpmcnByzf/9+s2fPHrNo0SIjyWzYsKGjttAqVVVV3n+GJZmVK1ea4uJi8/XXXxtj2vd8Ezid1Nq1a42kJh8Xk2TWrl1rjDHmhx9+MGlpaaZv374mKCjI3HjjjWbGjBmmrKysA3bQOq3ZtzHnf3V4yZIlJjo62jidTvOzn/3M7N69u51Xf3VmzJjR5L63bNniHWPb+TbG930bY8f5NsaY7777zjz00EOmV69eplevXuahhx5q9GvCNpzzV155xfTr1890797dDB8+3GzdutX72owZM8yYMWMajM/PzzfDhg0z3bt3N/Hx8ea1115r5xW3DV/2nZ2dbfr372+Cg4PNddddZ2677TazcePGDlj11bnw6+6XPmbMmGGMad/z7TDmv3fzAAAAWILfogIAANYhcAAAgHUIHAAAYB0CBwAAWIfAAQAA1iFwAACAdQgcAABgHQIHAABYh8ABAADWIXAAAIB1CBwAAGAdAgcAAFjn/wE/KVECQrywZQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_samples = 5000\n",
    "events_test = np.random.uniform(low=-1, high=1, size=(test_samples, vector_dimension))\n",
    "z = model.encoder(events_test)\n",
    "interval_test = calculateInterval(events_test)\n",
    "\n",
    "plt.scatter(interval_test, z, s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a732e6b2-8f51-4cd2-8116-11b95e66f467",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
